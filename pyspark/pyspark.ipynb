{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36808,
     "status": "ok",
     "timestamp": 1614974358236,
     "user": {
      "displayName": "Tri",
      "photoUrl": "",
      "userId": "18100809214550483764"
     },
     "user_tz": 480
    },
    "id": "6fwzoGqCwIpC",
    "outputId": "c5551c31-75d7-4c28-e8b0-f05fc6e00432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
      "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
      "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
      "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
      "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
      "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\" PySpark setup \"\"\"\n",
    "\n",
    "# Find the latest version of spark 3.0 from http://www-us.apache.org/dist/spark/ and enter as the spark version environment variable\n",
    "import os\n",
    "spark_version = 'spark-3.0.2'\n",
    "os.environ['SPARK_VERSION'] = spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"JAVA_HOME\"] = '/usr/lib/jvm/java-11-openjdk-amd64'\n",
    "os.environ[\"SPARK_HOME\"] = f'/content/{spark_version}-bin-hadoop2.7'\n",
    "\n",
    "# Locate Spark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "executionInfo": {
     "elapsed": 36985,
     "status": "ok",
     "timestamp": 1614974365721,
     "user": {
      "displayName": "Tri",
      "photoUrl": "",
      "userId": "18100809214550483764"
     },
     "user_tz": 480
    },
    "id": "iOq8Kqjt0wTB",
    "outputId": "6a7258bd-7a23-4ed0-d2c4-fedad34fe02a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://29d0762d05b6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6f74b9a1d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependencies\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Spark session\n",
    "spark = SparkSession.builder.appName('app').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1614976746204,
     "user": {
      "displayName": "Tri",
      "photoUrl": "",
      "userId": "18100809214550483764"
     },
     "user_tz": 480
    },
    "id": "TltENMGS_4DS",
    "outputId": "38071b24-5f6c-419f-f114-e86b29fadf00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- food: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      "\n",
      "+-------+-----+\n",
      "|   food|price|\n",
      "+-------+-----+\n",
      "|  pizza|    0|\n",
      "|  sushi|   12|\n",
      "|chinese|   10|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add food data from S3\n",
    "food_url = 'https://s3.amazonaws.com/dataviz-curriculum/day_1/food.csv'\n",
    "spark.sparkContext.addFile(food_url)\n",
    "\n",
    "# Define food schema\n",
    "fields = [\n",
    "  StructField('food', StringType(), nullable=True),\n",
    "  StructField('price', IntegerType(), nullable=True)\n",
    "]\n",
    "schema = StructType(fields=fields)\n",
    "\n",
    "# Read in food data\n",
    "food_df = spark.read.csv(SparkFiles.get('food.csv'), schema=schema, sep=',', header=True)\n",
    "food_df.printSchema() # schema\n",
    "food_df.show() # head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1614976782064,
     "user": {
      "displayName": "Tri",
      "photoUrl": "",
      "userId": "18100809214550483764"
     },
     "user_tz": 480
    },
    "id": "PqgjumOkA1ep",
    "outputId": "0f05608d-04ee-4db3-ef7e-1f93b9176aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+\n",
      "|   food|price|half_price|\n",
      "+-------+-----+----------+\n",
      "|  pizza|    0|       0.0|\n",
      "|  sushi|   12|       6.0|\n",
      "|chinese|   10|       5.0|\n",
      "+-------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add new discount column\n",
    "food_df = food_df.withColumn('discount', food_df['price'] / 2)\n",
    "food_df = food_df.withColumnRenamed('discount', 'half_price') # rename new column\n",
    "food_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11526,
     "status": "ok",
     "timestamp": 1614976799057,
     "user": {
      "displayName": "Tri",
      "photoUrl": "",
      "userId": "18100809214550483764"
     },
     "user_tz": 480
    },
    "id": "ODwZNeSGBKqO",
    "outputId": "1cae000b-ac9e-4b77-d6b0-d86ae315b0eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- designation: string (nullable = true)\n",
      " |-- points: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- province: string (nullable = true)\n",
      " |-- region_1: string (nullable = true)\n",
      " |-- region_2: string (nullable = true)\n",
      " |-- variety: string (nullable = true)\n",
      " |-- winery: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+------+-----+--------------+-----------------+-----------------+------------------+--------------------+\n",
      "|country|         description|         designation|points|price|      province|         region_1|         region_2|           variety|              winery|\n",
      "+-------+--------------------+--------------------+------+-----+--------------+-----------------+-----------------+------------------+--------------------+\n",
      "|     US|This tremendous 1...|   Martha's Vineyard|    96|  235|    California|      Napa Valley|             Napa|Cabernet Sauvignon|               Heitz|\n",
      "|  Spain|Ripe aromas of fi...|Carodorum Selecci...|    96|  110|Northern Spain|             Toro|             null|     Tinta de Toro|Bodega Carmen Rod...|\n",
      "|     US|Mac Watson honors...|Special Selected ...|    96|   90|    California|   Knights Valley|           Sonoma|   Sauvignon Blanc|            Macauley|\n",
      "|     US|This spent 20 mon...|             Reserve|    96|   65|        Oregon|Willamette Valley|Willamette Valley|        Pinot Noir|               Ponzi|\n",
      "| France|This is the top w...|         La Br��lade|    95|   66|      Provence|           Bandol|             null|Provence red blend|Domaine de la B̩gude|\n",
      "+-------+--------------------+--------------------+------+-----+--------------+-----------------+-----------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add wine data\n",
    "wine_url = 'https://s3.amazonaws.com/dataviz-curriculum/day_1/wine.csv'\n",
    "spark.sparkContext.addFile(wine_url)\n",
    "\n",
    "# Read in wine data\n",
    "wine_df = spark.read.csv(SparkFiles.get('wine.csv'), sep=',', header=True)\n",
    "wine_df.printSchema()\n",
    "wine_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4031,
     "status": "ok",
     "timestamp": 1614976807033,
     "user": {
      "displayName": "Tri",
      "photoUrl": "",
      "userId": "18100809214550483764"
     },
     "user_tz": 480
    },
    "id": "0LsUndPkds1u",
    "outputId": "1cf76532-009d-43f9-c94f-85e2a77e31c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      avg(points)|\n",
      "+-----------------+\n",
      "|87.88834105383143|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show average points\n",
    "wine_df.select(avg('points')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2020,
     "status": "ok",
     "timestamp": 1614976912968,
     "user": {
      "displayName": "Tri",
      "photoUrl": "",
      "userId": "18100809214550483764"
     },
     "user_tz": 480
    },
    "id": "5zh45mHjdJzs",
    "outputId": "a0d492f3-40e8-4bfc-f830-61aa89c41c8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------+-----+--------------+\n",
      "| country|         designation|points|price|       variety|\n",
      "+--------+--------------------+------+-----+--------------+\n",
      "|      US|                null|    94|   19|  Muscat Blanc|\n",
      "|   Spain|Cardenal Cisneros...|    94|   15| Pedro Xim̩nez|\n",
      "|      US|         Dijon Clone|    94|   18|    Chardonnay|\n",
      "|      US|Stone's Throw Vin...|    94|   18|      Riesling|\n",
      "|Portugal|                null|    94|   19|Portuguese Red|\n",
      "+--------+--------------------+------+-----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort wines under $20 by descending points (with SQL filtering)\n",
    "selected_cols = ['country', 'designation', 'points', 'price', 'variety']\n",
    "cheap_wines = wine_df.filter('price < 20').select(selected_cols).orderBy(wine_df['points'].desc()) # transformation\n",
    "cheap_wines.show(5) # action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3149,
     "status": "ok",
     "timestamp": 1614976916153,
     "user": {
      "displayName": "Tri",
      "photoUrl": "",
      "userId": "18100809214550483764"
     },
     "user_tz": 480
    },
    "id": "sEp6CqJLflPd",
    "outputId": "4dbf2fef-8444-4a62-e150-a10876004b05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+-----+----------+--------------------+-----------+--------------------+---------------+\n",
      "|country|         description|         designation|points|price|  province|            region_1|   region_2|             variety|         winery|\n",
      "+-------+--------------------+--------------------+------+-----+----------+--------------------+-----------+--------------------+---------------+\n",
      "|     US|Sweet in blackber...|     Single Vineyard|    87|  100|California|          Yountville|       Napa|  Cabernet Sauvignon|    Ghost Block|\n",
      "|     US|This lush wine ep...|            Red Wine|    94|  100|California|         Napa Valley|       Napa|Bordeaux-style Re...|         Viader|\n",
      "|     US|A beautiful, rich...|           J. Schram|    94|  100|California|         North Coast|North Coast|     Sparkling Blend|    Schramsberg|\n",
      "|     US|Pricy, but flashy...|     Single Vineyard|    90|  100|California|          Yountville|       Napa|  Cabernet Sauvignon|    Ghost Block|\n",
      "|     US|This is the best ...|Litton Estate Vin...|    98|  100|California|Russian River Valley|     Sonoma|          Pinot Noir|Williams Selyem|\n",
      "+-------+--------------------+--------------------+------+-----+----------+--------------------+-----------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort California wines over $15 by price (with Python filtering)\n",
    "wine_df.filter((wine_df['province'] == 'California') & (wine_df['price'] > 15)).orderBy(wine_df['price']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlWLmAmtg25w"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMt9jIDAN5RtpESvE6M1Fer",
   "collapsed_sections": [],
   "name": "pyspark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
