# PySpark Basics with AWS

This mini-project explores dataframes, natural language processing (NLP), and the extract-transform-load (ETL) pipeline with PySpark. Furthermore, this will include reading in data from AWS simple storage service (S3) and loading data to a database on AWS relational database service (RDS). These notebooks were created on Google Colab, so they may not run properly elsewhere.

## License

This repository is licensed under the MIT license.