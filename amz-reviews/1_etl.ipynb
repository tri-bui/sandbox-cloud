{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Review ETL\n",
    "\n",
    "This is an extract-transform-load (ETL) pipeline for Amazon pet product reviews data. The process for each step in the pipeline is outlined in the section description.\n",
    "\n",
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22011,
     "status": "ok",
     "timestamp": 1615142195086,
     "user": {
      "displayName": "Tri",
      "photoUrl": "",
      "userId": "18100809214550483764"
     },
     "user_tz": 480
    },
    "id": "lwN0ixmqLNBo",
    "outputId": "e1c64d49-b063-4ebf-cf97-130f45acf0aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  979k  100  979k    0     0  1059k      0 --:--:-- --:--:-- --:--:-- 1058k\n"
     ]
    }
   ],
   "source": [
    "# Download a Postgres driver to allow Spark to interact with Postgres\n",
    "!curl -O https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22325,
     "status": "ok",
     "timestamp": 1615142195461,
     "user": {
      "displayName": "Tri",
      "photoUrl": "",
      "userId": "18100809214550483764"
     },
     "user_tz": 480
    },
    "id": "7roME6jkLP08",
    "outputId": "7975985a-d743-4b44-9b46-e0188f4db2bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.4.26:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>amz</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa47f7a09d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locate Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Dependencies\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import col\n",
    "from config import rds, db_props\n",
    "\n",
    "# Spark session adding the Postgres driver to Spark\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName('amz') \\\n",
    "                    .config('spark.driver.extraClassPath', 'postgresql-42.2.16.jar') \\\n",
    "                    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 45496,
     "status": "aborted",
     "timestamp": 1615142219396,
     "user": {
      "displayName": "Tri",
      "photoUrl": "",
      "userId": "18100809214550483764"
     },
     "user_tz": 480
    },
    "id": "wnVJ_PWP6F75"
   },
   "source": [
    "### Extract\n",
    "\n",
    "1. Read in the data using the S3 url for pet products (from the data source below)\n",
    "2. Sample 4% of the data\n",
    "    - We will be working with a subsample of the data to shorten the load time\n",
    "\n",
    "Source: https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " marketplace       | US                                                                                                                                                                                                                                                           \n",
      " customer_id       | 28794885                                                                                                                                                                                                                                                     \n",
      " review_id         | REAKC26P07MDN                                                                                                                                                                                                                                                \n",
      " product_id        | B00Q0K9604                                                                                                                                                                                                                                                   \n",
      " product_parent    | 510387886                                                                                                                                                                                                                                                    \n",
      " product_title     | (8-Pack) EZwhelp Belly Band/Wrap                                                                                                                                                                                                                             \n",
      " product_category  | Pet Products                                                                                                                                                                                                                                                 \n",
      " star_rating       | 5                                                                                                                                                                                                                                                            \n",
      " helpful_votes     | 0                                                                                                                                                                                                                                                            \n",
      " total_votes       | 0                                                                                                                                                                                                                                                            \n",
      " vine              | N                                                                                                                                                                                                                                                            \n",
      " verified_purchase | Y                                                                                                                                                                                                                                                            \n",
      " review_headline   | A great purchase for \"dribbly\" dogs                                                                                                                                                                                                                          \n",
      " review_body       | Best belly bands on the market!  These are a great deal for an 8 pack.  Before we had 2 of another brand and we were constantly washing them and the velcro kept getting loose.  These are secure and with 8 in a pack, you can put on a fresh one each day. \n",
      " review_date       | 2015-08-31                                                                                                                                                                                                                                                   \n",
      "-RECORD 1-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " marketplace       | US                                                                                                                                                                                                                                                           \n",
      " customer_id       | 11488901                                                                                                                                                                                                                                                     \n",
      " review_id         | R3NU7OMZ4HQIEG                                                                                                                                                                                                                                               \n",
      " product_id        | B00MBW5O9W                                                                                                                                                                                                                                                   \n",
      " product_parent    | 912374672                                                                                                                                                                                                                                                    \n",
      " product_title     | Warren Eckstein's Hugs & Kisses Vitamin Mineral Supplement Treat for Dogs                                                                                                                                                                                    \n",
      " product_category  | Pet Products                                                                                                                                                                                                                                                 \n",
      " star_rating       | 2                                                                                                                                                                                                                                                            \n",
      " helpful_votes     | 0                                                                                                                                                                                                                                                            \n",
      " total_votes       | 1                                                                                                                                                                                                                                                            \n",
      " vine              | N                                                                                                                                                                                                                                                            \n",
      " verified_purchase | Y                                                                                                                                                                                                                                                            \n",
      " review_headline   | My dogs love Hugs and Kisses                                                                                                                                                                                                                                 \n",
      " review_body       | My dogs love Hugs and Kisses.  However, the last time I bought a $40.00+ bottle from Amazon....something was wrong with them.  They are all stuck together and seemed moist.  Usually they are not.  Had to throw them out.                                  \n",
      " review_date       | 2015-08-31                                                                                                                                                                                                                                                   \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add file\n",
    "data_bucket = 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/'\n",
    "data_file = 'amazon_reviews_us_Pet_Products_v1_00.tsv.gz'\n",
    "spark.sparkContext.addFile(data_bucket + data_file)\n",
    "\n",
    "# Read in data\n",
    "df = spark.read.csv(SparkFiles.get(data_file), sep='\\t', header=True, inferSchema=True)\n",
    "df.show(2, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: integer (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2643619"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schema and row count\n",
    "df.printSchema()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105644"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample 4% of rows\n",
    "df_sample = df.sample(fraction=0.04, seed=0)\n",
    "df_sample.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "\n",
    "Create a dataframe for each of the 4 tables in the database, with the corresponding columns:\n",
    "1. **`reviews`** - `review_id`, `customer_id`, `product_id`, `product_parent`, `review_date`\n",
    "2. **`products`** - `product_id`, `product_title`\n",
    "3. **`customers`** - `customer_id`, `review_count`\n",
    "4. **`vine`** - `review_id`, `star_rating`, `helpful_votes`, `total_votes`, `vine`, `verified_purchase`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105644\n",
      "+--------------+-----------+----------+--------------+-----------+\n",
      "|     review_id|customer_id|product_id|product_parent|review_date|\n",
      "+--------------+-----------+----------+--------------+-----------+\n",
      "|R1000CIZTRNP23|   25423435|B00K1B6RCI|     308737701| 2015-03-06|\n",
      "|R1004OFK0BIRO3|   27253416|B002MY58G8|     165494310| 2013-02-24|\n",
      "|R10060FLI507JX|   12505859|B000L3XYZ4|     501118658| 2015-01-10|\n",
      "|R1006BO4DMPE0K|   22756793|B00CD6LYD6|      19412506| 2013-09-22|\n",
      "|R1007R17B2A71O|   27891829|B003QS6JL2|     936104171| 2013-06-23|\n",
      "+--------------+-----------+----------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Review table\n",
    "review_cols = ['review_id', 'customer_id', 'product_id', 'product_parent', df_sample['review_date'].cast(DateType())]\n",
    "review_df = df_sample.select(review_cols).orderBy('review_id')\n",
    "print(review_df.count())\n",
    "review_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42329\n",
      "+----------+--------------------+\n",
      "|product_id|       product_title|\n",
      "+----------+--------------------+\n",
      "|039480001X|  The Cat in the Hat|\n",
      "|0876051468|The Stray Cat Han...|\n",
      "|0975412817|The Notes Pocket ...|\n",
      "|0983794812|Pathway Cat Journ...|\n",
      "|1223000893|Cat Sitter DVD Tr...|\n",
      "+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Product table\n",
    "product_df = df_sample.select(['product_id', 'product_title']).dropDuplicates().orderBy('product_id')\n",
    "print(product_df.count())\n",
    "product_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98486\n",
      "+-----------+------------+\n",
      "|customer_id|review_count|\n",
      "+-----------+------------+\n",
      "|      10318|           1|\n",
      "|      10368|           1|\n",
      "|      10449|           1|\n",
      "|      11125|           2|\n",
      "|      11618|           1|\n",
      "+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Customer table\n",
    "customer_df = df_sample.groupBy('customer_id').count().orderBy('customer_id')\n",
    "customer_df = customer_df.withColumnRenamed('count', 'review_count')\n",
    "print(customer_df.count())\n",
    "customer_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105644\n",
      "+--------------+-----------+-------------+-----------+----+-----------------+\n",
      "|     review_id|star_rating|helpful_votes|total_votes|vine|verified_purchase|\n",
      "+--------------+-----------+-------------+-----------+----+-----------------+\n",
      "|R1000CIZTRNP23|          4|            3|          3|   N|                Y|\n",
      "|R1004OFK0BIRO3|          5|          138|        141|   N|                N|\n",
      "|R10060FLI507JX|          5|            0|          0|   N|                Y|\n",
      "|R1006BO4DMPE0K|          5|            0|          0|   N|                Y|\n",
      "|R1007R17B2A71O|          5|            1|          1|   N|                Y|\n",
      "+--------------+-----------+-------------+-----------+----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vine table\n",
    "vine_cols = ['review_id', 'star_rating', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase']\n",
    "vine_df = df_sample.select(vine_cols).orderBy('review_id')\n",
    "print(vine_df.count())\n",
    "vine_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load\n",
    "\n",
    "1. Create a file named `config.py` in the same directory as this notebook\n",
    "2. Create a PostgreSQL database on AWS Relational Database Service (RDS) and save its endpoint and port in `config.py` with the following format:<br />\n",
    "    rds = {\n",
    "        \"endpoint\": \"db-identifier.qwerty1234.us-region.rds.amazonaws.com\",\n",
    "        \"port\": \"5432\"\n",
    "    }\n",
    "3. Use the endpoint and port to create a new server on pgAdmin\n",
    "4. Create a new database in the server and save its information in `config.py` with the following format:<br />\n",
    "    db_props = {\n",
    "        \"name\": \"db-name\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"password\",\n",
    "        \"driver\": \"org.postgresql.Driver\",\n",
    "        \"mode\": \"overwrite\"\n",
    "    }\n",
    "5. Run the code in `schema.sql` on pgAdmin to create the tables inside the database\n",
    "6. Load the 4 dataframes created in the transform step into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to database on RDS\n",
    "jdbc_url = f\"jdbc:postgresql://{rds['endpoint']}:{rds['port']}/{db_props['name']}\"\n",
    "\n",
    "# Configure RDS settings\n",
    "mode = db_props['mode']\n",
    "properties = {\n",
    "    \"user\": db_props['user'],\n",
    "    \"password\": db_props['password'],\n",
    "    \"driver\": db_props['driver']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o101.jdbc.\n: org.postgresql.util.PSQLException: The connection attempt failed.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:315)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:225)\n\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n\tat org.postgresql.Driver.connect(Driver.java:264)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:48)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:46)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:90)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:963)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:963)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:415)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:399)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:791)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.net.UnknownHostException: amz-reviews.cqzw4eyr0cqo.us-west-1.rds.amazonaws.com\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:196)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:394)\n\tat java.net.Socket.connect(Socket.java:606)\n\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n\t... 38 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f6093ba8e328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Write data to database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreview_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reviews'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mproduct_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'products'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcustomer_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'customers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvine_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/server/spark-3.0.1-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/server/spark-3.0.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/server/spark-3.0.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/server/spark-3.0.1-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o101.jdbc.\n: org.postgresql.util.PSQLException: The connection attempt failed.\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:315)\n\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:225)\n\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n\tat org.postgresql.Driver.connect(Driver.java:264)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:48)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:46)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:90)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:963)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:963)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:415)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:399)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:791)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.net.UnknownHostException: amz-reviews.cqzw4eyr0cqo.us-west-1.rds.amazonaws.com\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:196)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:394)\n\tat java.net.Socket.connect(Socket.java:606)\n\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n\t... 38 more\n"
     ]
    }
   ],
   "source": [
    "# Write data to database\n",
    "review_df.write.jdbc(url=jdbc_url, table='reviews', mode=mode, properties=properties)\n",
    "product_df.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=properties)\n",
    "customer_df.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=properties)\n",
    "vine_df.write.jdbc(url=jdbc_url, table='vine', mode=mode, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the data was loaded into the db\n",
    "spark.read.format('jdbc') \\\n",
    "          .option(\"url\", jdbc_url) \\\n",
    "          .option(\"dbtable\", 'reviews') \\\n",
    "          .option(\"user\", properties['user']) \\\n",
    "          .option(\"password\", properties['password']) \\\n",
    "          .option(\"driver\", properties['driver']) \\\n",
    "          .load().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOGYybMYiiz1JzN6Wz9QV89",
   "collapsed_sections": [],
   "name": "etl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
